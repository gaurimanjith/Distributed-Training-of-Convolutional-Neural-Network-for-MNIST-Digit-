# Distributed-Training-of-Convolutional-Neural-Network-for-MNIST-Digit-
MNIST Digit Classification with Distributed Training

This project entails the development and training of a convolutional neural network (CNN) model for digit classification on the MNIST dataset. Leveraging TensorFlow and Keras, the CNN architecture was implemented, comprising convolutional, max-pooling, and dense layers. Distributed training across multiple devices was achieved using MirroredStrategy, enhancing training efficiency and scalability. Prior to training, the dataset underwent preprocessing, including pixel value normalization and splitting into training, validation, and test sets. The trained model achieved an impressive accuracy of [insert accuracy] on the test dataset, indicative of its robust performance. Evaluation metrics such as loss and accuracy were employed to assess the model's efficacy on unseen data. Additionally, the execution time of the training process was measured using the %%time magic command, ensuring efficient code optimization. This project underscores the effectiveness of distributed training for CNN models in digit classification tasks.






